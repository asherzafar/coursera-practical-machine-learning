---
title: "Practical Machine Learning - Prediction Assignment"
author: "Asher Zafar"
date: "December 4, 2017"
output: html_document
---

###Classifying Movements based on Accelerometer Data

The objective of this assignment is to develop a model that can accurately predict out-of-sample whether a movement belonds to one of five classes. My approach includes tidying the data, setting up controls and hyperparameter searches, and cross-validating the results to estimate the out-of-sample accuracy, as well as holding out a test set. Data for this project came from the [Human Activity Recognition project from Groupware@LES](http://groupware.les.inf.puc-rio.br/har). 

####Exploring the data
While there are 159 variables in the data set, only 53 had useful data in them (most were almost entirely blank and near zero variance). Metadata on specific users was dropped, as this might not be available for any future movements that are predicted. The remaining data was used to train 4 models. 70% of the data was used for training, and 3 fold cross-validation was used on this set (more folds or repeated CV would have been of little value for the computational time involved). Example code from the random forest (RF) model is presented below. Only selected code is in this markdown file. Full code for this assignment is available within this repo in the [model.R](https://github.com/asherzafar/coursera-practical-machine-learning/blob/master/model.R) file.

####Random Forest Model Code
```{r, eval=FALSE}
control <- trainControl(method="cv", number=3, summaryFunction = multiClassSummary, classProbs = TRUE) #Set controls
date() #Timestamp to view how long the model took to run
train.rf <- train(classe ~ ., data=train.m, method="rf", metric=metric, trControl=control, tuneLength=5) #Run model with controls. Metric was set to "Accuracy"
print(train.rf) #Print model results
plot(train.rf) #Plot accuracy under different hypertuning parameters
date()
```


####Model Comparison

The most accurate cross-validated random forest model with the hyperparameter mtry=14 (the number of sampled variables per split) was over 99% accurate. The only comparable model in performance were gradient boosted trees (GBM), though I also tested a single decision tree and SVM. Cross-validation folds had little variance in accuracy or AUC. Softmax regression was considered but not used given the performance of the tree ensembles.

```{r, echo=FALSE}
readRDS("model.comparison.plot.rds")
```

Applying the results to the held-out test data validate the expectations from the cross-validation. Both the RF and GBM were over 99% accurate. Confusion matrices indicated little pattern in errors, though some misclassifications were slightly higher than others.

####Random Forest Results

```{r, echo=FALSE}
readRDS("RFAcc.rds")
```

####Gradient Boosted Tree Results

```{r, echo=FALSE}
readRDS("GBMAcc.rds")
```

Based on these results, I predict the 20 entries held out for the "quiz" component of the assignment. Both models agree on the results for these 20 entries.

```{r, echo=FALSE}
readRDS("quiz.rds")
```

####Conclusions

Either the random forest or gradient boosted tree models would be more than suitable for this problem, with both achieving over 99% accuracy. Hyperparameters can be refined further and tested for compute time under parallel processing to determine the best model for an operational or real-time prediction setting.
